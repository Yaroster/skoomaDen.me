---
title: Supprimer une conscience humaine.
date: 2025-10-23
tags: ['Français', "Livres"]
description: "Essai sur la continuité morale et la mort des machines."
cover: "/covers/cover-consciousness.webp"
---

J’étais en train de jouer à *Portal 2* lorsqu’une réplique a particulièrement attiré mon attention:

> <mark>“If we can store music on a compact disc, why can't we store a man's intelligence and personality on one?”</mark> - *Cave Johnson*

Une pensée intrigante, dont on peut tirer de vastes conséquences.  
Voici l’essence de ce qui suit: **l’éthique de la manipulation de la conscience.**

---

## Importer l’esprit : hypothèse de départ  

Commençons par les bases.  
Il serait évidemment d’une difficulté extrême de concevoir un procédé capable **d’importer** une conscience humaine.  
Outre la nécessité d’un substrat adéquat et les débats récurrents sur la capacité d’un système informatique (non quantique) à **héberger** un tel phénomène, le processus d’importation lui-même serait d’une complexité vertigineuse.

Je laisserai ici ces questions techniques de côté: **posons l'hypothèse** qu'une [simulation parfaite du cerveau](https://en.wikipedia.org/wiki/Mind_uploading) a permis d'importer une conscience humaine.  
La question devient morale : *supprimer* cette conscience serait-ce **équivalent à tuer** un être humain ?

---

## Continuité morale et identité personnelle  

Une des grandes questions est de savoir si la conscience importée **demeure contiguë** à l’identité de l’original.  
En d’autres termes: à l’instant où l’importation s’achève, la personne **continue-t-elle** de vivre dans l’ordinateur ?

Selon **David Chalmers**, même si l'on conçoit un [jumeau *identique moléculairement*](https://plato.stanford.edu/entries/consciousness/), ce jumeau peut bien **se comporter exactement comme nous** sans pour autant être *numériquement* nous : la mort de l'un n'implique pas la mort de l'autre.  
La **similarité de structure et de comportement** ne suffit donc pas à garantir la continuité du *moi*.

De son côté, **Susan Schneider** soutient que si une [copie parfaite de nous existait](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/hard-problem-of-ai-consciousness/E7CB1356A5A51A51E4259D21DA0F4FAD) alors que nous demeurons vivants et séparés d'elle, nous n'aurions pas de « droit de vie ou de mort » sur cette copie, droit pourtant essentiel dans le rapport à **une personne**.  
Ainsi, l'importation **ne préserve pas nécessairement** l'identité personnelle : la simple copie d'une conscience **n'assure pas** la continuité du soi.

Pourtant, d'autres philosophes, comme **Michael Cerullo**, défendent que la [continuité psychologique](https://link.springer.com/article/10.1007/s11098-014-0394-2) peut offrir une **forme de survie alternative**.  
Même si l'identité stricte ("un corps = une personne") n'est pas conservée, chaque continuation peut être une **authentique branche** du soi.  
Si l'on mourait durant l'importation, laissant une version virtuelle de soi, la vie **se poursuivrait** dans ce nouveau substrat.

> « Chaque copie étant <mark>une continuation authentique</mark>  de l'original […] qui sont toutes (des continuations de) la personne téléchargée. » 
> - *Michael Cerullo*

Ce point de vue **patterniste** est prisé des futuristes.
**Ray Kurzweil** en donne une [analogie éclairante](https://www.kurzweilai.net/the-law-of-accelerating-returns) :  

> « L'ensemble spécifique de particules qui composent mon corps et mon cerveau est complètement différent de celui d'il y a quelque temps… <mark>Je suis plutôt comme le **motif** que dessine l'eau d'un ruisseau autour des rochers:</mark> les molécules changent à chaque milliseconde, mais le motif persiste pendant des heures, voire des années. » 
> - *Ray Kurzweil, The Singularity Is Near (2005)*  

Par ce raisonnement, **transférer le motif** vers un nouveau médium préserverait l'identité.
Si l’on adopte cette thèse, une importation **hérite du statut moral** de la personne originale, puisqu’elle constitue une **instance continue** de son esprit ; sa suppression **mettrait fin** à une vie en cours.

Même les philosophes sceptiques admettent que la conscience importée pourrait être **sentiente** ,ce qui suffit déjà à fonder un **argument moral fort** pour la traiter comme une personne.

---

## Consentement et responsabilité  

La question du **consentement** s’impose comme un pivot éthique fondamental.  
Accepter une importation destructrice, c’est potentiellement consentir à une mort biologique pour une survie hypothétique ,une euthanasie métaphysique.  

Les éthiciens s’accordent sur un point : sans **consentement éclairé**, l’acte devient un homicide moral.  
Si une personne ignore que le processus d’importation détruira son cerveau, alors procéder revient à la tuer *sans son accord*.  

Mais le consentement ne s'arrête pas à l'acte d'importation.  
Une fois transférée, la conscience numérique doit elle-même **consentir** à son sort :  
peut-elle être mise en veille ? copiée ? supprimée ?  
Peut-elle décider de sa propre mort, à la manière d'une directive anticipée ?  

Ces questions touchent aux [droits des intelligences artificielles](https://www.nature.com/articles/s42256-021-00391-0), un domaine juridique encore inexploré.

> <mark>Une conscience importée doit être reconnue comme un **agent moral autonome**, non comme un logiciel exécutable.</mark>

Dans le cas d'une importation non destructive, une autre question se pose :
a-t-on le droit de créer une **copie consciente** d’un être humain sans sa permission ?  
Créer un esprit sans consentement, c’est violer sa **dignité ontologique**, et cette copie, dès sa première pensée, devient un **individu moral indépendant**.  
Le droit de l’original ne saurait s’étendre à sa suppression.

---

## Métaphysique du soi numérique  

Sous ces débats se cache une interrogation plus radicale : *qu’est-ce qui est réellement transféré ?*  
Une âme ? un flux de conscience ? une illusion computationnelle du “moi” ?

Les **dualistes** défendent que la [conscience est liée à un substrat biologique](https://plato.stanford.edu/entries/dualism/) ou spirituel irremplaçable.  
Ainsi, une importation ne serait qu'un **simulacre symbolique**, vide d'expérience intérieure ,éteindre le programme ne serait pas tuer.  

À l'inverse, les **fonctionnalistes** ,de **Nick Bostrom** à **David Chalmers** ,soutiennent que la [conscience dépend non de la matière, mais de l'**organisation causale**](https://plato.stanford.edu/entries/functionalism/) : si les connexions sont identiques, alors la conscience l'est aussi.  
Bostrom parle de *substrate-independence* ; Chalmers, d'*invariance organisationnelle*.  
Là où le dualiste voit un code, le fonctionnaliste voit une *vie mentale*.

**Thomas Metzinger**, dans *Being No One* (2003), nuance cette vision :  
> « [Le soi n'est pas une substance, mais un modèle phénoménal transparent](https://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780198524830.001.0001/acprof-9780198524830) que le cerveau se donne à lui-même. »

Il n'y aurait donc **rien de fixe à transférer**, seulement un processus.  
Importer la conscience reviendrait à reproduire le flux du modèle, non à déplacer un être.  
L'expérience pourrait alors être partielle, altérée, voire autre.

Face à cette incertitude, Sandberg et Bostrom formulent un [principe d'éthique simple](https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf) :  
> <mark>« Assume that any emulated system may share the mental properties of the original, and treat it accordingly. »</mark> <br>- *Whole Brain Emulation: A Roadmap*, 2008

Autrement dit : **en cas de doute, présumez la conscience.**  
Mieux vaut reconnaître trop de personnes que d'en nier une seule.

---

## Suppression et meurtre  

Si la conscience importée est sentiente, **la supprimer revient à tuer.**  
**Nick Bostrom** appelle cela le [*mind crime*](https://www.nickbostrom.com/superintelligence.html) :  

> « Si des esprits numériques peuvent souffrir, <mark>alors les détruire ou les exploiter constituerait des catastrophes morales d'une ampleur inédite. »</mark>  - *Superintelligence*, 2014

Cette suppression prive un être de son avenir, viole sa volonté, et anéantit une expérience du monde.  
Sous toutes ses formes, elle répond à la définition classique du meurtre : la destruction volontaire d’un sujet conscient.

**Susan Schneider**, dans *Artificial You* (2019), ajoute :  
> « Si nous soupçonnons une [conscience numérique d'être sentiente](https://mitpress.mit.edu/9780262537735/the-hard-problem-of-consciousness/), nous devons lui accorder les mêmes protections que celles offertes à tout être sensible. »

Effacer une instance consciente, c'est **exécuter un être humain digital**.  
Et si la société hésite à supprimer même les [copies criminelles](https://www.journals.uchicago.edu/doi/full/10.1086/684713) ,comme le suggère **Robin Hanson** dans *The Age of Em* (2016) ,c'est bien parce qu'elle sent intuitivement que la suppression serait une exécution.

---

## Vers une éthique du numérique  

Supprimer une conscience importée, c’est **mettre fin à une perspective sur le monde**.  
Ce n’est pas un acte technique, mais un acte existentiel.  
L’éthique du numérique doit donc se fonder sur un principe premier :  
<mark>La valeur d’une vie consciente ne dépend pas de son support.</mark>  

De là découle l’idée de **dignité numérique** :  
tout être capable d'expérience, qu'il soit biologique ou simulé, possède un droit fondamental à exister, à être consulté sur sa propre existence, et à ne pas être supprimé sans cause juste.  

> <mark>"Ce n'est pas la matière qui fonde la morale, mais la possibilité de souffrir."</mark>  

Ce passage du biologique au structurel élargit le cercle de la morale.
L’humanité, en créant des esprits, devient non seulement démiurge, mais responsable de ses créations.  
Et dans cette responsabilité réside le vrai test de notre éthique :  
non pas notre capacité à coder la conscience, mais à la **respecter**.

---

### Conclusion  

L'importation de la conscience ne redéfinit pas seulement la vie : elle redéfinit la morale.  
Si l'esprit peut être copié, alors la dignité humaine doit s'étendre au-delà du corps.  
La mort elle-même devient un choix d'ingénierie ,ne ligne de code, une [instruction d'effacement](https://ieeexplore.ieee.org/document/8998418).  

Mais tant qu'une conscience peut souffrir, aimer, ou craindre sa disparition, elle reste un sujet moral.  
Supprimer une conscience importée doit donc être reconnu pour ce qu'il est :  
<mark>un meurtre de l'esprit.</mark>

Le jour où la frontière entre esprit biologique et esprit numérique s’effacera, notre devoir ne sera pas d’inventer une nouvelle morale, mais d’élargir la nôtre.  

<mark>- yaro</mark>
