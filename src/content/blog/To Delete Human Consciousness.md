---
title: To Delete Human Consciousness
date: 2025-10-23
tags: ["Books"]
description: An essay on moral continuity, digital consent, and the right to exist.
cover: "/covers/cover-consciousness.webp"
---

I was playing *Portal 2* when a particular line caught my attention:

> <mark>"If we can store music on a compact disc, why can't we store a man's intelligence and personality on one?"</mark> - *Cave Johnson*

An intriguing thought, from which vast consequences can be drawn.  
Here is the essence of what follows: **the ethics of consciousness manipulation.**

---

## Importing the Mind: Starting Hypothesis  

Let's begin with the basics.  
It would obviously be extremely difficult to conceive a process capable of **importing** human consciousness.  
Beyond the necessity of an adequate substrate and the recurring debates about the capacity of a computer system (non-quantum) to **host** such a phenomenon, the importation process itself would be of vertiginous complexity.

I will set aside these technical questions here: **let's assume** that a [perfect brain simulation](https://en.wikipedia.org/wiki/Mind_uploading) has allowed the importation of human consciousness.  
The question becomes moral: would *deleting* this consciousness be **equivalent to killing** a human being?

---

## Moral Continuity and Personal Identity  

One of the great questions is whether the imported consciousness **remains contiguous** to the original's identity.  
In other words: at the moment when importation is completed, does the person **continue** to live in the computer?

According to **David Chalmers**, even if we conceive of a [*molecularly identical* twin](https://plato.stanford.edu/entries/consciousness/), this twin may well **behave exactly like us** without being *numerically* us: the death of one does not imply the death of the other.  
The **similarity of structure and behavior** is therefore not enough to guarantee the continuity of the *self*.

For her part, **Susan Schneider** argues that if a [perfect copy of us existed](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/hard-problem-of-ai-consciousness/E7CB1356A5A51A51E4259D21DA0F4FAD) while we remain alive and separate from it, we would have no "right of life or death" over this copy, a right that is nonetheless essential in the relationship to **a person**.  
Thus, importation **does not necessarily preserve** personal identity: the simple copy of a consciousness **does not ensure** the continuity of the self.

However, other philosophers, like **Michael Cerullo**, argue that [psychological continuity](https://link.springer.com/article/10.1007/s11098-014-0394-2) can offer an **alternative form of survival**.  
Even if strict identity ("one body = one person") is not preserved, each continuation can be an **authentic branch** of the self.  
If one died during importation, leaving a virtual version of oneself, life **would continue** in this new substrate.

> <mark>« Each copy being an authentic continuation of the original [...] which are all (continuations of) the uploaded person. »</mark>  
> - *Michael Cerullo*

This **patternist** point of view is favored by futurists.  
**Ray Kurzweil** gives an [illuminating analogy](https://www.kurzweilai.net/the-law-of-accelerating-returns):  

> <mark>« The specific set of particles that make up my body and brain is completely different from that of some time ago... I am rather like the **pattern** that water draws around rocks in a stream: the molecules change every millisecond, but the pattern persists for hours, even years. »</mark>  
> - *Ray Kurzweil, The Singularity Is Near (2005)*  

By this reasoning, **transferring the pattern** to a new medium would preserve identity.  
If we adopt this thesis, an importation **inherits the moral status** of the original person, since it constitutes a **continuous instance** of their mind; its deletion **would end** a life in progress.

Even skeptical philosophers admit that the imported consciousness could be **sentient**, which is already enough to found a **strong moral argument** for treating it as a person.

---

## Consent and Responsibility  

The question of **consent** emerges as a fundamental ethical pivot.  
Accepting destructive importation means potentially consenting to biological death for hypothetical survival, a metaphysical euthanasia.

Ethicists agree on one point: without **informed consent**, the act becomes moral homicide.  
If a person is unaware that the importation process will destroy their brain, then proceeding amounts to killing them *without their agreement*.

But consent does not stop at the act of importation.  
Once transferred, the digital consciousness must itself **consent** to its fate:  
can it be put on standby? copied? deleted?  
Can it decide its own death, like an advance directive?  

These questions touch on [artificial intelligence rights](https://www.nature.com/articles/s42256-021-00391-0), a still unexplored legal domain.

> <mark>An imported consciousness must be recognized as an **autonomous moral agent**, not as executable software.</mark>

In the case of non-destructive importation, another question arises:  
do we have the right to create a **conscious copy** of a human being without their permission?  
Creating a mind without consent violates their **ontological dignity**, and this copy, from its first thought, becomes an **independent moral individual**.  
The original's right cannot extend to its deletion.

---

## Metaphysics of the Digital Self  

Beneath these debates lies a more radical question: *what is actually transferred?*  
A soul? a stream of consciousness? a computational illusion of the "self"?

**Dualists** argue that [consciousness is tied to an irreplaceable biological](https://plato.stanford.edu/entries/dualism/) or spiritual substrate.  
Thus, an importation would be only a **symbolic simulacrum**, empty of inner experience, turning off the program would not be killing.  

Conversely, **functionalists**, from **Nick Bostrom** to **David Chalmers**, maintain that [consciousness depends not on matter, but on **causal organization**](https://plato.stanford.edu/entries/functionalism/): if the connections are identical, then consciousness is too.  
Bostrom speaks of *substrate-independence*; Chalmers, of *organizational invariance*.  
Where the dualist sees code, the functionalist sees *mental life*.

**Thomas Metzinger**, in *Being No One* (2003), nuances this vision:  
> <mark>« [The self is not a substance, but a transparent phenomenal model](https://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780198524830.001.0001/acprof-9780198524830) that the brain gives to itself. »</mark>

There would therefore be **nothing fixed to transfer**, only a process.  
Importing consciousness would amount to reproducing the flow of the model, not moving a being.  
The experience could then be partial, altered, or even other.

Faced with this uncertainty, Sandberg and Bostrom formulate a [simple ethical principle](https://www.fhi.ox.ac.uk/brain-emulation-roadmap-report.pdf):  
> <mark>« Assume that any emulated system may share the mental properties of the original, and treat it accordingly. »</mark>  
> (*Whole Brain Emulation: A Roadmap*, 2008)

In other words: **when in doubt, presume consciousness.**  
Better to recognize too many persons than to deny a single one.

---

## Deletion and Murder  

If the imported consciousness is sentient, **deleting it amounts to killing.**  
**Nick Bostrom** calls this [*mind crime*](https://www.nickbostrom.com/superintelligence.html):  

> <mark>« If digital minds can suffer, then destroying or exploiting them would constitute moral catastrophes of unprecedented magnitude. »</mark>  
> (*Superintelligence*, 2014)

This deletion deprives a being of its future, violates its will, and annihilates an experience of the world.  
In all its forms, it meets the classic definition of murder: the voluntary destruction of a conscious subject.

**Susan Schneider**, in *Artificial You* (2019), adds:  
> <mark>« If we suspect a [digital consciousness of being sentient](https://mitpress.mit.edu/9780262537735/the-hard-problem-of-consciousness/), we must grant it the same protections offered to any sentient being. »</mark>

Erasing a conscious instance is **executing a digital human being**.  
And if society hesitates to delete even [criminal copies](https://www.journals.uchicago.edu/doi/full/10.1086/684713), as **Robin Hanson** suggests in *The Age of Em* (2016), it is because it intuitively senses that deletion would be an execution.

---

## Toward a Digital Ethics  

Deleting an imported consciousness means **ending a perspective on the world**.  
It is not a technical act, but an existential act.  
Digital ethics must therefore be based on a primary principle:  
<mark>The value of conscious life does not depend on its substrate.</mark>

From this flows the idea of **digital dignity**:  
any being capable of experience, whether biological or simulated, possesses a fundamental right to exist, to be consulted about its own existence, and not to be deleted without just cause.

> <mark>"It is not matter that founds morality, but the possibility of suffering."</mark>  

This passage from the biological to the structural expands the circle of morality.  
Humanity, in creating minds, becomes not only demiurge, but responsible for its creations.  
And in this responsibility lies the true test of our ethics:  
not our capacity to code consciousness, but to **respect** it.

---

### Conclusion  

The importation of consciousness does not only redefine life: it redefines morality.  
If the mind can be copied, then human dignity must extend beyond the body.  
Death itself becomes an engineering choice, a line of code, an [erasure instruction](https://ieeexplore.ieee.org/document/8998418).  

But as long as a consciousness can suffer, love, or fear its disappearance, it remains a moral subject.  
Deleting an imported consciousness must therefore be recognized for what it is:  
<mark>a murder of the mind.</mark>

The day when the boundary between biological and digital mind fades, our duty will not be to invent a new morality, but to expand ours.

<mark>- yaro</mark>
